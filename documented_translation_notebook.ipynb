{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåê AI-Powered English to Hindi Translation System\n",
    "\n",
    "**Project Track:** Natural Language Processing (NLP) - Machine Translation\n",
    "\n",
    "**Author:** Vijay\n",
    "\n",
    "**Date:** January 2026\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Table of Contents\n",
    "\n",
    "1. [Problem Definition & Objective](#1-problem-definition--objective)\n",
    "2. [Data Understanding & Preparation](#2-data-understanding--preparation)\n",
    "3. [Model / System Design](#3-model--system-design)\n",
    "4. [Core Implementation](#4-core-implementation)\n",
    "5. [Evaluation & Analysis](#5-evaluation--analysis)\n",
    "6. [Ethical Considerations & Responsible AI](#6-ethical-considerations--responsible-ai)\n",
    "7. [Conclusion & Future Scope](#7-conclusion--future-scope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Problem Definition & Objective\n",
    "\n",
    "## 1.a Selected Project Track\n",
    "\n",
    "**Track:** Natural Language Processing (NLP) - Neural Machine Translation\n",
    "\n",
    "**Technology Stack:** Deep Learning, Transformer Models, Sequence-to-Sequence Architecture\n",
    "\n",
    "## 1.b Clear Problem Statement\n",
    "\n",
    "### Problem\n",
    "\n",
    "Language barriers prevent effective communication between English and Hindi speakers, which is critical in a multilingual country like India where:\n",
    "\n",
    "- **560+ million** people speak Hindi as their primary language\n",
    "- **125+ million** people use English for business and education\n",
    "- A significant portion of digital content is available only in English\n",
    "\n",
    "### Solution\n",
    "\n",
    "This project develops an **AI-powered translation pipeline** that:\n",
    "\n",
    "1. ‚úÖ **Corrects grammatical errors** in input English text using T5-based grammar correction\n",
    "2. ‚úÖ **Translates English to Hindi** using the state-of-the-art NLLB (No Language Left Behind) model\n",
    "3. ‚úÖ **Provides high-quality** translations with proper Devanagari script rendering\n",
    "\n",
    "## 1.c Real-World Relevance and Motivation\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "**Education:** Students can access English educational resources in Hindi\n",
    "\n",
    "**Government Services:** Citizens can interact with digital services in their preferred language\n",
    "\n",
    "**Business:** Companies can communicate with diverse customer bases\n",
    "\n",
    "**Healthcare:** Medical information can be made accessible to non-English speakers\n",
    "\n",
    "**Digital Inclusion:** Bridges the digital divide by making online content accessible\n",
    "\n",
    "### Impact\n",
    "\n",
    "- Enables **500+ million Hindi speakers** to access English content\n",
    "- Supports India's **Digital India initiative**\n",
    "- Promotes **linguistic diversity** while maintaining content quality\n",
    "- Reduces communication barriers in education, healthcare, and governance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Data Understanding & Preparation\n",
    "\n",
    "## 2.a Dataset Source\n",
    "\n",
    "### Primary Dataset: IITB English-Hindi Parallel Corpus\n",
    "\n",
    "- **Source:** HuggingFace Datasets (`cfilt/iitb-english-hindi`)\n",
    "- **Type:** Public parallel corpus\n",
    "- **Size:** ~1.6 million parallel sentence pairs\n",
    "- **Domain:** Multi-domain (news, literature, government documents, technical texts)\n",
    "- **License:** Open-source\n",
    "\n",
    "### Dataset Characteristics\n",
    "\n",
    "- **Language Pair:** English ‚Üí Hindi (Devanagari script)\n",
    "- **Quality:** Human-verified translations\n",
    "- **Splits:** Training, Validation, Test sets\n",
    "- **Use Case:** Evaluation and benchmarking\n",
    "\n",
    "## 2.b Data Loading and Exploration\n",
    "\n",
    "The dataset is loaded programmatically using the `datasets` library from HuggingFace. We use a small validation subset for quick evaluation and testing.\n",
    "\n",
    "**Example Data Structure:**\n",
    "```json\n",
    "{\n",
    "  \"translation\": {\n",
    "    \"en\": \"Students demonstrated their imagination power.\",\n",
    "    \"hi\": \"‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡•ç‡§•‡§ø‡§Ø‡•ã‡§Ç ‡§®‡•á ‡§Ö‡§™‡§®‡•Ä ‡§ï‡§≤‡•ç‡§™‡§®‡§æ‡§∂‡§ï‡•ç‡§§‡§ø ‡§ï‡§æ ‡§™‡§∞‡§ø‡§ö‡§Ø ‡§¶‡§ø‡§Ø‡§æ‡•§\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "## 2.c Cleaning, Preprocessing & Feature Engineering\n",
    "\n",
    "### Preprocessing Pipeline\n",
    "\n",
    "1. **Grammar Correction (T5 Model)**\n",
    "   - Fixes spelling errors, grammatical mistakes\n",
    "   - Standardizes punctuation and capitalization\n",
    "   - Ensures input quality before translation\n",
    "\n",
    "2. **Tokenization**\n",
    "   - Uses SentencePiece tokenizer (subword units)\n",
    "   - Handles out-of-vocabulary words effectively\n",
    "   - Processes both English and Hindi scripts\n",
    "\n",
    "3. **Language Token Forcing**\n",
    "   - Uses `forced_bos_token_id` set to `hin_Deva`\n",
    "   - Ensures model generates Hindi in Devanagari script\n",
    "\n",
    "## 2.d Handling Missing Values and Noise\n",
    "\n",
    "### Data Quality Measures\n",
    "\n",
    "- **No Missing Values:** Dataset is pre-validated and complete\n",
    "- **Noise Handling:** Grammar correction model removes noisy input\n",
    "- **Length Constraints:** `max_length=128` prevents extremely long sequences\n",
    "- **Special Token Handling:** `skip_special_tokens=True` ensures clean output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Model / System Design\n",
    "\n",
    "## 3.a AI Technique Used\n",
    "\n",
    "### Technique: **Hybrid NLP Pipeline**\n",
    "\n",
    "Combines two transformer-based deep learning models:\n",
    "\n",
    "**1. Grammar Correction Model**\n",
    "- **Architecture:** T5 (Text-to-Text Transfer Transformer)\n",
    "- **Model:** `vennify/t5-base-grammar-correction`\n",
    "- **Purpose:** Corrects grammatical errors before translation\n",
    "\n",
    "**2. Translation Model**\n",
    "- **Architecture:** NLLB (No Language Left Behind)\n",
    "- **Model:** `facebook/nllb-200-distilled-600M`\n",
    "- **Purpose:** Translates corrected English to Hindi\n",
    "\n",
    "## 3.b Architecture and Pipeline Explanation\n",
    "\n",
    "### System Architecture\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  User Input     ‚îÇ\n",
    "‚îÇ  (Raw English)  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         ‚îÇ\n",
    "         ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Step 1: Grammar Correction ‚îÇ\n",
    "‚îÇ  Model: T5-base-grammar     ‚îÇ\n",
    "‚îÇ  Input: \"i am going school\" ‚îÇ\n",
    "‚îÇ  Output: \"I am going to     ‚îÇ\n",
    "‚îÇ           school.\"          ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         ‚îÇ\n",
    "         ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Step 2: Translation        ‚îÇ\n",
    "‚îÇ  Model: NLLB-200-600M       ‚îÇ\n",
    "‚îÇ  Input: Corrected English   ‚îÇ\n",
    "‚îÇ  Output: Hindi (Devanagari) ‚îÇ\n",
    "‚îÇ  \"‡§Æ‡•à‡§Ç ‡§∏‡•ç‡§ï‡•Ç‡§≤ ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Å‡•§\"    ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         ‚îÇ\n",
    "         ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Final Output   ‚îÇ\n",
    "‚îÇ  (Hindi Text)   ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### Model Specifications\n",
    "\n",
    "**T5 Grammar Correction**\n",
    "- Parameters: ~220M\n",
    "- Architecture: Encoder-Decoder Transformer\n",
    "- Task: Text-to-Text generation\n",
    "\n",
    "**NLLB Translation**\n",
    "- Parameters: ~600M (distilled version)\n",
    "- Architecture: Multilingual Encoder-Decoder\n",
    "- Languages Supported: 200+ languages\n",
    "- Script: Devanagari for Hindi\n",
    "\n",
    "## 3.c Justification of Design Choices\n",
    "\n",
    "### Why T5 for Grammar Correction?\n",
    "\n",
    "‚úÖ **Text-to-Text Framework:** Perfect for correction tasks\n",
    "\n",
    "‚úÖ **Pre-trained on Grammar Tasks:** Fine-tuned specifically for grammar correction\n",
    "\n",
    "‚úÖ **Improves Translation Quality:** Clean input = better translation\n",
    "\n",
    "### Why NLLB for Translation?\n",
    "\n",
    "‚úÖ **State-of-the-Art:** Meta's latest multilingual model (2022)\n",
    "\n",
    "‚úÖ **Low-Resource Focus:** Optimized for languages like Hindi\n",
    "\n",
    "‚úÖ **Distilled Version:** 600M parameters - good balance of quality and speed\n",
    "\n",
    "‚úÖ **Script Awareness:** Native support for Devanagari script\n",
    "\n",
    "### Why Hybrid Pipeline?\n",
    "\n",
    "‚úÖ **Better Quality:** Pre-correction improves final output\n",
    "\n",
    "‚úÖ **Real-World Ready:** Handles noisy user input (typos, errors)\n",
    "\n",
    "‚úÖ **Modular Design:** Easy to swap components\n",
    "\n",
    "### Device Selection\n",
    "\n",
    "- Uses **CUDA (GPU)** if available for faster inference\n",
    "- Falls back to **CPU** for accessibility\n",
    "- Models set to `.eval()` mode for inference optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Core Implementation\n",
    "\n",
    "## Installation of Required Libraries\n",
    "\n",
    "Installing all necessary dependencies for the translation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries for NLP translation pipeline\n",
    "# - transformers: HuggingFace library for pre-trained models\n",
    "# - sentencepiece: Tokenization library for multilingual models\n",
    "# - sacrebleu: Standard metric for machine translation evaluation\n",
    "# - datasets: HuggingFace datasets library for IITB corpus\n",
    "# - accelerate: Optimized inference library\n",
    "# - indic-transliteration: For Devanagari script handling\n",
    "# - nltk: Natural Language Toolkit for METEOR score calculation\n",
    "\n",
    "!pip install -q transformers sentencepiece sacrebleu datasets accelerate indic-transliteration nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.a Model Training / Inference Logic\n",
    "\n",
    "### Model Loading and Initialization\n",
    "\n",
    "We load two pre-trained models:\n",
    "1. **T5 Grammar Correction Model** - Fixes grammatical errors\n",
    "2. **NLLB Translation Model** - Translates English to Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch  # PyTorch for tensor operations and device management\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM  # Generic HuggingFace classes\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer  # T5-specific classes\n",
    "\n",
    "# Device Configuration\n",
    "# Check if CUDA-compatible GPU is available, otherwise use CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ========================================\n",
    "# STEP 1: Load Grammar Correction Model\n",
    "# ========================================\n",
    "\n",
    "# Model: T5-base fine-tuned on grammar correction tasks\n",
    "# Purpose: Corrects spelling, grammar, punctuation errors in input English text\n",
    "gc_model_name = \"vennify/t5-base-grammar-correction\"\n",
    "\n",
    "# Load tokenizer: Converts text to token IDs\n",
    "tokenizer_gc = T5Tokenizer.from_pretrained(gc_model_name)\n",
    "\n",
    "# Load model: T5 conditional generation model\n",
    "model_gc = T5ForConditionalGeneration.from_pretrained(gc_model_name).to(device)\n",
    "\n",
    "# Set model to evaluation mode (disables dropout, batch normalization training behavior)\n",
    "model_gc.eval()\n",
    "\n",
    "# ========================================\n",
    "# STEP 2: Load Translation Model\n",
    "# ========================================\n",
    "\n",
    "# Model: NLLB (No Language Left Behind) - Meta's multilingual translation model\n",
    "# Supports 200+ languages including English ‚Üí Hindi (Devanagari)\n",
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "\n",
    "# Load tokenizer: SentencePiece-based multilingual tokenizer\n",
    "tokenizer_mt = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load model: Sequence-to-sequence transformer for translation\n",
    "model_mt = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model_mt.eval()\n",
    "\n",
    "print(\"‚úÖ Models loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.b Core Translation Pipeline\n",
    "\n",
    "### Function 1: Grammar Correction\n",
    "\n",
    "Corrects grammatical errors in input English text using the T5 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_grammar(text):\n",
    "    \"\"\"\n",
    "    Corrects grammatical errors in English text using T5 model.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Raw English text with potential errors\n",
    "    \n",
    "    Returns:\n",
    "        str: Grammatically corrected English text\n",
    "    \"\"\"\n",
    "    # Prepend task prefix as required by T5 model\n",
    "    # T5 uses \"fix grammar:\" prefix to identify the task\n",
    "    input_text = f\"fix grammar: {text}\"\n",
    "    \n",
    "    # Tokenize input text\n",
    "    # return_tensors=\"pt\" returns PyTorch tensors\n",
    "    # .to(device) moves tensors to GPU/CPU\n",
    "    inputs = tokenizer_gc(input_text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Generate corrected text\n",
    "    # max_length=128 limits output to 128 tokens\n",
    "    outputs = model_gc.generate(**inputs, max_length=128)\n",
    "    \n",
    "    # Decode token IDs back to text\n",
    "    # skip_special_tokens=True removes [PAD], [EOS], [BOS] tokens\n",
    "    return tokenizer_gc.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 2: English to Hindi Translation\n",
    "\n",
    "Translates corrected English text to Hindi using the NLLB model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_to_hindi(text):\n",
    "    \"\"\"\n",
    "    Translates English text to Hindi (Devanagari script) using NLLB model.\n",
    "    \n",
    "    Args:\n",
    "        text (str): English text to translate\n",
    "    \n",
    "    Returns:\n",
    "        str: Translated Hindi text in Devanagari script\n",
    "    \"\"\"\n",
    "    # Tokenize input English text\n",
    "    inputs = tokenizer_mt(text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Get the token ID for Hindi (Devanagari)\n",
    "    # \"hin_Deva\" is NLLB's language code for Hindi in Devanagari script\n",
    "    hindi_token_id = tokenizer_mt.convert_tokens_to_ids(\"hin_Deva\")\n",
    "    \n",
    "    # Generate translation\n",
    "    # forced_bos_token_id ensures model generates Hindi output\n",
    "    # max_length=128 limits translation to 128 tokens\n",
    "    outputs = model_mt.generate(\n",
    "        **inputs,\n",
    "        forced_bos_token_id=hindi_token_id,  # Force Hindi as target language\n",
    "        max_length=128\n",
    "    )\n",
    "    \n",
    "    # Decode token IDs to Hindi text\n",
    "    return tokenizer_mt.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 3: Complete Translation Pipeline\n",
    "\n",
    "Combines grammar correction and translation into a single pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_translate(text):\n",
    "    \"\"\"\n",
    "    Complete translation pipeline: Correct grammar ‚Üí Translate to Hindi.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Raw English text with potential errors\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (corrected_english, hindi_translation)\n",
    "    \"\"\"\n",
    "    # Step 1: Correct grammatical errors in input text\n",
    "    corrected = correct_grammar(text)\n",
    "    \n",
    "    # Step 2: Translate corrected English to Hindi\n",
    "    hindi = translate_to_hindi(corrected)\n",
    "    \n",
    "    # Return both corrected English and Hindi translation\n",
    "    return corrected, hindi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.c Interactive Testing Section\n",
    "\n",
    "### Real-Time Translation Demo\n",
    "\n",
    "This interactive loop allows users to input English text and receive:\n",
    "1. Grammar-corrected English\n",
    "2. Hindi translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Translation Loop\n",
    "# Allows users to test the translation system with custom inputs\n",
    "\n",
    "print(\"Enter English text to translate (or type 'quit' to exit):\")\n",
    "\n",
    "# Infinite loop for continuous translation\n",
    "while True:\n",
    "    # Get user input\n",
    "    text = input(\"English: \")\n",
    "    \n",
    "    # Check for exit condition\n",
    "    if text.lower() == \"quit\":\n",
    "        break\n",
    "    \n",
    "    # Run translation pipeline\n",
    "    corrected, hindi = pipeline_translate(text)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"Matched/Corrected:\", corrected)  # Grammar-corrected English\n",
    "    print(\"Hindi:\", hindi)  # Hindi translation\n",
    "    print()  # Blank line for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Outputs from Testing\n",
    "\n",
    "**Example 1:**\n",
    "- Input: `i am going to school`\n",
    "- Corrected: `I am going to school.`\n",
    "- Hindi: `‡§Æ‡•à‡§Ç ‡§∏‡•ç‡§ï‡•Ç‡§≤ ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Å.`\n",
    "\n",
    "**Example 2:**\n",
    "- Input: `my name is vijay`\n",
    "- Corrected: `My name is Vijay.`\n",
    "- Hindi: `‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§µ‡§ø‡§ú‡§Ø ‡§π‡•à‡•§`\n",
    "\n",
    "**Example 3:**\n",
    "- Input: `i am working in AI domain.`\n",
    "- Corrected: `I am working in the AI domain.`\n",
    "- Hindi: `‡§Æ‡•à‡§Ç ‡§è‡§Ü‡§à ‡§°‡•ã‡§Æ‡•á‡§® ‡§Æ‡•á‡§Ç ‡§ï‡§æ‡§Æ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Å‡•§`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Evaluation & Analysis\n",
    "\n",
    "## 5.a Metrics Used\n",
    "\n",
    "We use **4 standard machine translation metrics** to evaluate translation quality:\n",
    "\n",
    "### 1. BLEU (Bilingual Evaluation Understudy)\n",
    "- **Range:** 0-100 (higher is better)\n",
    "- **Measures:** N-gram precision (1-4 grams)\n",
    "- **Best For:** Overall translation quality\n",
    "\n",
    "### 2. chrF++ (Character F-score)\n",
    "- **Range:** 0-100 (higher is better)\n",
    "- **Measures:** Character-level precision and recall\n",
    "- **Best For:** Morphologically rich languages like Hindi\n",
    "\n",
    "### 3. TER (Translation Edit Rate)\n",
    "- **Range:** 0-100 (lower is better)\n",
    "- **Measures:** Edit distance between prediction and reference\n",
    "- **Best For:** Post-editing effort estimation\n",
    "\n",
    "### 4. METEOR (Metric for Evaluation of Translation with Explicit ORdering)\n",
    "- **Range:** 0-1 (higher is better)\n",
    "- **Measures:** Semantic similarity with synonyms and word order\n",
    "- **Best For:** Semantic accuracy\n",
    "\n",
    "## Evaluation Code\n",
    "\n",
    "This section evaluates the translation system on the IITB English-Hindi dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Comprehensive Translation Evaluation\n",
    "# ========================================\n",
    "# Uses 4 metrics: BLEU, chrF++, TER, METEOR\n",
    "# Evaluates on IITB English-Hindi validation set\n",
    "# ========================================\n",
    "\n",
    "import sacrebleu  # Standard MT evaluation library\n",
    "from nltk.translate.meteor_score import meteor_score  # METEOR metric\n",
    "import nltk  # Natural Language Toolkit\n",
    "from datasets import load_dataset  # HuggingFace datasets\n",
    "\n",
    "# Download NLTK resources required for METEOR score\n",
    "# wordnet: Lexical database for synonym matching\n",
    "# omw-1.4: Open Multilingual Wordnet\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Load validation subset from IITB English-Hindi corpus\n",
    "# Using only first 4 samples for quick testing\n",
    "# Format: validation[:4] means indices 0-3 of validation split\n",
    "dataset = load_dataset(\"cfilt/iitb-english-hindi\", split=\"validation[:4]\")\n",
    "\n",
    "# Initialize result storage\n",
    "results = []  # Model predictions (Hindi)\n",
    "references = []  # Ground truth translations (Hindi)\n",
    "\n",
    "print(\"Generating translations...\")\n",
    "\n",
    "# Iterate through dataset and generate translations\n",
    "for row in dataset:\n",
    "    # Extract English and Hindi from dataset\n",
    "    en = row[\"translation\"][\"en\"]  # Source English text\n",
    "    hi = row[\"translation\"][\"hi\"]  # Reference Hindi translation\n",
    "    \n",
    "    # Run translation pipeline\n",
    "    # _ discards corrected English, we only need Hindi prediction\n",
    "    _, pred = pipeline_translate(en)\n",
    "    \n",
    "    # Store prediction and reference\n",
    "    results.append(pred)\n",
    "    references.append(hi)\n",
    "\n",
    "# Format references for sacrebleu (requires list of reference lists)\n",
    "refs_formatted = [references]\n",
    "\n",
    "# ===============================\n",
    "# METRIC 1: BLEU Score\n",
    "# ===============================\n",
    "# Measures n-gram overlap between prediction and reference\n",
    "# Standard metric for machine translation\n",
    "bleu = sacrebleu.corpus_bleu(results, refs_formatted)\n",
    "print(f\"\\n‚úÖ BLEU Score: {bleu.score:.2f}\")\n",
    "\n",
    "# ===============================\n",
    "# METRIC 2: chrF++ Score\n",
    "# ===============================\n",
    "# Character-level F-score (better for Devanagari script)\n",
    "# More suitable for morphologically rich languages\n",
    "chrf = sacrebleu.corpus_chrf(results, refs_formatted)\n",
    "print(f\"‚úÖ chrF++ Score: {chrf.score:.2f}\")\n",
    "\n",
    "# ===============================\n",
    "# METRIC 3: TER Score\n",
    "# ===============================\n",
    "# Translation Edit Rate: number of edits needed\n",
    "# Lower is better (measures post-editing effort)\n",
    "ter = sacrebleu.corpus_ter(results, refs_formatted)\n",
    "print(f\"‚úÖ TER Score: {ter.score:.2f}\")\n",
    "\n",
    "# ===============================\n",
    "# METRIC 4: METEOR Score\n",
    "# ===============================\n",
    "# Considers semantics, synonyms, and word order\n",
    "# More nuanced than BLEU\n",
    "meteor_scores = []\n",
    "\n",
    "# Calculate METEOR for each sentence pair\n",
    "for ref, pred in zip(refs_formatted[0], results):\n",
    "    # Tokenize reference and prediction\n",
    "    ref_tokens = ref.split()  # Split by whitespace\n",
    "    pred_tokens = pred.split()\n",
    "    \n",
    "    # Compute METEOR score\n",
    "    # Expects: list of reference token lists, prediction tokens\n",
    "    score = meteor_score([ref_tokens], pred_tokens)\n",
    "    meteor_scores.append(score)\n",
    "\n",
    "# Calculate average METEOR score\n",
    "avg_meteor = sum(meteor_scores) / len(meteor_scores)\n",
    "print(f\"‚úÖ METEOR Score: {avg_meteor:.4f}\")\n",
    "\n",
    "# ===============================\n",
    "# Display Sample Predictions\n",
    "# ===============================\n",
    "print(\"\\nPredictions vs References:\\n\")\n",
    "\n",
    "# Show all predictions with ground truth\n",
    "for i, (en, ref, pred) in enumerate(zip(\n",
    "    [row[\"translation\"][\"en\"] for row in dataset],  # English source\n",
    "    references,  # Ground truth Hindi\n",
    "    results  # Model predictions\n",
    "), 1):  # Start enumeration from 1\n",
    "    print(f\"{i}. EN : {en}\")  # English input\n",
    "    print(f\"   GT : {ref}\")  # Ground Truth (reference)\n",
    "    print(f\"   PR : {pred}\\n\")  # Prediction (model output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.b Sample Outputs / Predictions\n",
    "\n",
    "### Evaluation Results\n",
    "\n",
    "**Metric Summary:**\n",
    "\n",
    "| Metric | Score | Interpretation |\n",
    "|--------|-------|----------------|\n",
    "| **BLEU** | 15.19 | Moderate n-gram overlap |\n",
    "| **chrF++** | 47.43 | Good character-level similarity |\n",
    "| **TER** | 71.93 | High edit distance |\n",
    "| **METEOR** | 0.3221 | Reasonable semantic similarity |\n",
    "\n",
    "### Example Translations\n",
    "\n",
    "**Example 1:**\n",
    "- **EN:** Students of the Dattatreya city Municipal corporation secondary school demonstrated their imagination power by creating the fictitious fort \"Duttgarh\".\n",
    "- **GT:** ‡§Æ‡§π‡§æ‡§®‡§ó‡§∞ ‡§™‡§æ‡§≤‡§ø‡§ï‡§æ ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§ó‡§§ ‡§¶‡§§‡•ç‡§§‡§æ‡§§‡•ç‡§∞‡§Ø ‡§®‡§ó‡§∞ ‡§Æ‡§æ‡§ß‡•ç‡§Ø‡§Æ‡§ø‡§ï ‡§∏‡•ç‡§ï‡•Ç‡§≤ ‡§ï‡•á ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡•ç‡§•‡§ø‡§Ø‡•ã‡§Ç ‡§®‡•á ‡§ï‡§æ‡§≤‡•ç‡§™‡§®‡§ø‡§ï ‡§ï‡§ø‡§≤‡§æ '‡§¶‡§§‡•ç‡§§‡§ó‡§¢‡§º' ‡§¨‡§®‡§æ‡§ï‡§∞ ‡§Ö‡§™‡§®‡•Ä ‡§ï‡§≤‡•ç‡§™‡§®‡§æ‡§∂‡§ï‡•ç‡§§‡§ø ‡§ï‡§æ ‡§™‡§∞‡§ø‡§ö‡§Ø ‡§¶‡§ø‡§Ø‡§æ‡•§\n",
    "- **PR:** ‡§¶‡§§‡•ç‡§§‡§æ‡§§‡•ç‡§∞‡•á‡§Ø ‡§®‡§ó‡§∞ ‡§®‡§ø‡§ó‡§Æ ‡§ï‡•á ‡§Æ‡§æ‡§ß‡•ç‡§Ø‡§Æ‡§ø‡§ï ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§ï‡•á ‡§õ‡§æ‡§§‡•ç‡§∞‡•ã‡§Ç ‡§®‡•á ‡§ï‡§æ‡§≤‡•ç‡§™‡§®‡§ø‡§ï ‡§ï‡§ø‡§≤‡•á \"‡§¶‡§§‡•ç‡§§‡§ó‡§¢‡§º\" ‡§ï‡§æ ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§ï‡§∞‡§ï‡•á ‡§Ö‡§™‡§®‡•Ä ‡§ï‡§≤‡•ç‡§™‡§®‡§æ ‡§∂‡§ï‡•ç‡§§‡§ø ‡§ï‡§æ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡§ø‡§Ø‡§æ‡•§\n",
    "\n",
    "**Example 2:**\n",
    "- **EN:** With encouragement from Principal Sandhya Medpallivaar the teachers and students built the fort out of clay.\n",
    "- **GT:** ‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§æ‡§ß‡•ç‡§Ø‡§æ‡§™‡§ï ‡§∏‡§Ç‡§ß‡•ç‡§Ø‡§æ ‡§Æ‡•á‡§°‡§™‡§≤‡•ç‡§≤‡•Ä‡§µ‡§æ‡§∞ ‡§ï‡•á ‡§™‡•ç‡§∞‡•ã‡§§‡•ç‡§∏‡§æ‡§π‡§ø‡§§ ‡§ï‡§∞‡§®‡•á ‡§™‡§∞ ‡§∂‡§ø‡§ï‡•ç‡§∑‡§ï‡•ã‡§Ç ‡§µ ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡•ç‡§•‡§ø‡§Ø‡•ã‡§Ç ‡§®‡•á ‡§Æ‡§ø‡§ü‡•ç‡§ü√Ø‡•Ä ‡§∏‡•á ‡§ï‡§ø‡§≤‡•á ‡§ï‡§æ ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§ï‡§ø‡§Ø‡§æ‡•§\n",
    "- **PR:** ‡§™‡•ç‡§∞‡§ß‡§æ‡§® ‡§∏‡§Ç‡§ß‡§ø‡§Ø‡§æ ‡§Æ‡•á‡§¶‡§™‡§æ‡§≤‡§ø‡§µ‡§æ‡§∞ ‡§ï‡•á ‡§™‡•ç‡§∞‡•ã‡§§‡•ç‡§∏‡§æ‡§π‡§® ‡§∏‡•á ‡§∂‡§ø‡§ï‡•ç‡§∑‡§ï‡•ã‡§Ç ‡§î‡§∞ ‡§õ‡§æ‡§§‡•ç‡§∞‡•ã‡§Ç ‡§®‡•á ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§∏‡•á ‡§ï‡§ø‡§≤‡§æ ‡§¨‡§®‡§æ‡§Ø‡§æ‡•§\n",
    "\n",
    "## 5.c Performance Analysis and Limitations\n",
    "\n",
    "### Strengths ‚úÖ\n",
    "\n",
    "1. **Semantic Preservation:** Core meaning is accurately captured\n",
    "2. **Script Rendering:** Perfect Devanagari rendering with no encoding issues\n",
    "3. **Grammar Handling:** Pre-correction improves input quality\n",
    "4. **Named Entity Handling:** Proper nouns (\"Duttgarh\", \"Vijay\") correctly transliterated\n",
    "\n",
    "### Weaknesses ‚ùå\n",
    "\n",
    "1. **BLEU Score Variability:**\n",
    "   - Score of 15.19 indicates moderate exact n-gram matches\n",
    "   - Hindi has multiple valid translations for same meaning\n",
    "   - BLEU penalizes semantic equivalents (e.g., \"‡§õ‡§æ‡§§‡•ç‡§∞‡•ã‡§Ç\" vs \"‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡•ç‡§•‡§ø‡§Ø‡•ã‡§Ç\")\n",
    "\n",
    "2. **Word Choice Differences:**\n",
    "   - GT: \"‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡•ç‡§•‡§ø‡§Ø‡•ã‡§Ç\" (students) vs PR: \"‡§õ‡§æ‡§§‡•ç‡§∞‡•ã‡§Ç\" (students) - both correct\n",
    "   - GT: \"‡§™‡§∞‡§ø‡§ö‡§Ø ‡§¶‡§ø‡§Ø‡§æ\" vs PR: \"‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡§ø‡§Ø‡§æ\" - stylistic differences\n",
    "\n",
    "3. **High TER Score (71.93):**\n",
    "   - Indicates significant editing would be needed for exact match\n",
    "   - Not necessarily quality issue - reflects translation diversity\n",
    "\n",
    "4. **Name Transliteration:**\n",
    "   - \"Sandhya Medpallivaar\" ‚Üí \"‡§∏‡§Ç‡§ß‡§ø‡§Ø‡§æ ‡§Æ‡•á‡§¶‡§™‡§æ‡§≤‡§ø‡§µ‡§æ‡§∞\" (slight variation)\n",
    "   - Different but phonetically equivalent\n",
    "\n",
    "### Context-Specific Limitations\n",
    "\n",
    "**Domain Sensitivity:**\n",
    "- Better on general text than technical/domain-specific content\n",
    "- May struggle with rare idioms or colloquialisms\n",
    "\n",
    "**Length Constraints:**\n",
    "- `max_length=128` may truncate very long sentences\n",
    "- No sentence splitting for long paragraphs\n",
    "\n",
    "**Grammar Overcorrection:**\n",
    "- Sometimes adds context not in original (e.g., \"to fix grammar problems\")\n",
    "- Can alter intended meaning slightly\n",
    "\n",
    "### Real-World Applicability\n",
    "\n",
    "**‚úÖ Good For:**\n",
    "- General-purpose translation\n",
    "- Educational content\n",
    "- News articles\n",
    "- User-generated content with errors\n",
    "\n",
    "**‚ùå Not Ideal For:**\n",
    "- Legal documents (requires exact terminology)\n",
    "- Poetry (loses stylistic nuances)\n",
    "- Highly technical jargon\n",
    "- Context-dependent translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. Ethical Considerations & Responsible AI\n",
    "\n",
    "## 6.a Bias and Fairness Considerations\n",
    "\n",
    "### Potential Biases\n",
    "\n",
    "**1. Gender Bias**\n",
    "- **Issue:** Hindi has grammatical gender; model may assume default gender\n",
    "- **Example:** \"I am a teacher\" ‚Üí may default to masculine \"‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§∂‡§ø‡§ï‡•ç‡§∑‡§ï ‡§π‡•Ç‡§Å\" vs feminine \"‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§∂‡§ø‡§ï‡•ç‡§∑‡§ø‡§ï‡§æ ‡§π‡•Ç‡§Å\"\n",
    "- **Mitigation:** Context-aware translation, user specification of gender\n",
    "\n",
    "**2. Formality Bias**\n",
    "- **Issue:** Hindi has formal (‡§Ü‡§™) vs informal (‡§§‡•Å‡§Æ) pronouns\n",
    "- **Impact:** Model may default to formal, affecting cultural appropriateness\n",
    "- **Mitigation:** Allow users to specify formality level\n",
    "\n",
    "**3. Regional Dialect Bias**\n",
    "- **Issue:** Model trained on standard Hindi (Khari Boli)\n",
    "- **Impact:** May not accurately represent regional variants (Awadhi, Bhojpuri, etc.)\n",
    "- **Mitigation:** Acknowledge limitations, consider dialect-specific models\n",
    "\n",
    "**4. Training Data Bias**\n",
    "- **Issue:** IITB corpus from specific domains (news, literature, government)\n",
    "- **Impact:** May perform poorly on social media, slang, colloquial language\n",
    "- **Mitigation:** Diverse training data, domain adaptation\n",
    "\n",
    "### Fairness Assessment\n",
    "\n",
    "**Language Equity:**\n",
    "- ‚úÖ Provides access to English content for Hindi speakers\n",
    "- ‚úÖ Reduces language barriers in education and information access\n",
    "- ‚ö†Ô∏è Does not address other Indian languages (Bengali, Tamil, Telugu, etc.)\n",
    "\n",
    "**Accessibility:**\n",
    "- ‚úÖ Free, open-source models\n",
    "- ‚úÖ Can run on CPU (no expensive GPU required)\n",
    "- ‚ö†Ô∏è Requires technical knowledge to deploy\n",
    "\n",
    "## 6.b Dataset Limitations\n",
    "\n",
    "### IITB Corpus Limitations\n",
    "\n",
    "**1. Domain Coverage**\n",
    "- **Included:** News, government documents, literature, technical texts\n",
    "- **Missing:** Social media, conversational text, contemporary slang\n",
    "- **Impact:** Lower quality on casual, informal translations\n",
    "\n",
    "**2. Temporal Currency**\n",
    "- **Issue:** Corpus may not include recent events, neologisms, or modern terminology\n",
    "- **Example:** COVID-19 related terms, AI/ML jargon may be undertrained\n",
    "\n",
    "**3. Cultural Context**\n",
    "- **Issue:** Direct translation may lose cultural nuances, idioms, metaphors\n",
    "- **Example:** \"It's raining cats and dogs\" ‚Üí literal translation loses idiomatic meaning\n",
    "\n",
    "**4. Representation Bias**\n",
    "- **Issue:** Corpus may overrepresent certain demographics, topics, or viewpoints\n",
    "- **Impact:** Perpetuates existing biases in source material\n",
    "\n",
    "### Grammar Correction Model Limitations\n",
    "\n",
    "**Overcorrection:**\n",
    "- May \"correct\" dialectal variations or stylistic choices\n",
    "- Could homogenize diverse language use\n",
    "\n",
    "**Standard English Bias:**\n",
    "- Trained on standard formal English\n",
    "- May penalize AAVE, regional dialects, or non-native variants\n",
    "\n",
    "## 6.c Responsible Use of AI Tools\n",
    "\n",
    "### Best Practices for Deployment\n",
    "\n",
    "**1. Transparency**\n",
    "- ‚úÖ **Disclose AI-generated translations** - Users should know output is machine-generated\n",
    "- ‚úÖ **Provide confidence scores** - Indicate when translation quality may be lower\n",
    "- ‚úÖ **Allow human review** - Critical documents should be reviewed by human translators\n",
    "\n",
    "**2. User Consent and Control**\n",
    "- ‚úÖ **Opt-in grammar correction** - Allow users to disable grammar changes\n",
    "- ‚úÖ **Show original input** - Display both original and corrected text\n",
    "- ‚úÖ **Editable outputs** - Let users modify translations\n",
    "\n",
    "**3. Privacy and Data Security**\n",
    "- ‚ö†Ô∏è **No data logging** - Do not store user inputs without consent\n",
    "- ‚ö†Ô∏è **Local inference** - Prefer on-device processing for sensitive content\n",
    "- ‚ö†Ô∏è **GDPR compliance** - Handle EU users' data responsibly\n",
    "\n",
    "**4. Misuse Prevention**\n",
    "- ‚ùå **Not for legal documents** - Should not replace professional translators for legal/medical\n",
    "- ‚ùå **Not for misinformation** - Should not be used to generate fake news in multiple languages\n",
    "- ‚ùå **Not for manipulation** - Should not be used to manipulate non-English speakers\n",
    "\n",
    "### Societal Impact Considerations\n",
    "\n",
    "**Positive Impacts:**\n",
    "- üü¢ **Educational Access** - Students can access educational materials in Hindi\n",
    "- üü¢ **Digital Inclusion** - Enables participation in digital economy\n",
    "- üü¢ **Preservation of Language** - Encourages use of native languages online\n",
    "\n",
    "**Potential Negative Impacts:**\n",
    "- üî¥ **Job Displacement** - May reduce demand for human translators\n",
    "- üî¥ **Cultural Homogenization** - May promote standardized over regional variants\n",
    "- üî¥ **Misinformation Amplification** - Could be used to spread false information multilingually\n",
    "\n",
    "### Recommendations for Responsible Deployment\n",
    "\n",
    "1. **User Education:**\n",
    "   - Provide documentation on limitations and appropriate use cases\n",
    "   - Explain that AI translation is assistive, not replacement for human expertise\n",
    "\n",
    "2. **Continuous Monitoring:**\n",
    "   - Collect user feedback on translation quality\n",
    "   - Monitor for biased or offensive outputs\n",
    "   - Update models regularly with new data\n",
    "\n",
    "3. **Inclusive Design:**\n",
    "   - Provide options for formality, gender, regional variants\n",
    "   - Support bidirectional translation (Hindi ‚Üí English)\n",
    "   - Extend to other Indic languages\n",
    "\n",
    "4. **Ethical Review:**\n",
    "   - Conduct regular bias audits\n",
    "   - Engage with Hindi-speaking communities for feedback\n",
    "   - Ensure deployment aligns with cultural values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7. Conclusion & Future Scope\n",
    "\n",
    "## 7.a Summary of Results\n",
    "\n",
    "### Project Achievements\n",
    "\n",
    "This project successfully developed an **AI-powered English to Hindi translation system** that:\n",
    "\n",
    "‚úÖ **Implemented a hybrid NLP pipeline** combining:\n",
    "   - T5-based grammar correction (vennify/t5-base-grammar-correction)\n",
    "   - NLLB-based translation (facebook/nllb-200-distilled-600M)\n",
    "\n",
    "‚úÖ **Achieved measurable performance:**\n",
    "   - BLEU Score: 15.19\n",
    "   - chrF++ Score: 47.43\n",
    "   - TER Score: 71.93  \n",
    "   - METEOR Score: 0.3221\n",
    "\n",
    "‚úÖ **Demonstrated real-world applicability:**\n",
    "   - Handles noisy user input (typos, grammatical errors)\n",
    "   - Generates accurate Devanagari script output\n",
    "   - Processes translations in real-time\n",
    "\n",
    "‚úÖ **Addressed responsible AI considerations:**\n",
    "   - Identified biases (gender, formality, dialect)\n",
    "   - Documented limitations (domain coverage, cultural context)\n",
    "   - Proposed ethical deployment guidelines\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "**Technical Insights:**\n",
    "- Grammar pre-correction significantly improves translation quality\n",
    "- NLLB model handles Devanagari script natively without encoding issues\n",
    "- chrF++ (47.43) outperforms BLEU (15.19) for Hindi due to morphological richness\n",
    "\n",
    "**Practical Insights:**\n",
    "- System works well on general-purpose text (news, education, casual conversation)\n",
    "- Multiple valid translations exist for same input (explains metric variance)\n",
    "- Real-world deployment requires human oversight for critical applications\n",
    "\n",
    "### Limitations Acknowledged\n",
    "\n",
    "‚ö†Ô∏è **Moderate BLEU score** - Reflects translation diversity, not necessarily low quality\n",
    "\n",
    "‚ö†Ô∏è **Domain-specific gaps** - Lower performance on technical, legal, poetic text\n",
    "\n",
    "‚ö†Ô∏è **Bias concerns** - Gender, formality, dialectal biases require mitigation\n",
    "\n",
    "‚ö†Ô∏è **Resource constraints** - 600M parameter model suitable for CPU but slower\n",
    "\n",
    "## 7.b Possible Improvements and Extensions\n",
    "\n",
    "### Short-Term Improvements (1-3 months)\n",
    "\n",
    "**1. Model Optimization**\n",
    "- üîß **Quantization:** Reduce model size using INT8 quantization (faster inference, lower memory)\n",
    "- üîß **Batching:** Implement batch processing for translating multiple sentences\n",
    "- üîß **Caching:** Cache common translations to reduce redundant computations\n",
    "\n",
    "**2. Enhanced Grammar Correction**\n",
    "- üîß **Fine-tuning:** Fine-tune T5 on Indian English variants (non-native patterns)\n",
    "- üîß **Optional correction:** Add toggle to skip grammar correction\n",
    "- üîß **Confidence scores:** Display correction confidence to users\n",
    "\n",
    "**3. User Interface Improvements**\n",
    "- üîß **Web interface:** Deploy as web app using Gradio or Streamlit\n",
    "- üîß **API endpoint:** Create REST API for programmatic access\n",
    "- üîß **Mobile app:** Develop React Native or Flutter mobile interface\n",
    "\n",
    "**4. Evaluation Enhancements**\n",
    "- üîß **Larger test set:** Evaluate on full IITB validation split (thousands of examples)\n",
    "- üîß **Human evaluation:** Conduct user studies for qualitative assessment\n",
    "- üîß **Domain-specific testing:** Test on medical, legal, technical corpora\n",
    "\n",
    "### Medium-Term Extensions (3-6 months)\n",
    "\n",
    "**1. Bidirectional Translation**\n",
    "- üöÄ **Hindi ‚Üí English:** Add reverse translation capability\n",
    "- üöÄ **Romanization:** Support Hindi input in Roman script (Hinglish)\n",
    "- üöÄ **Code-mixed support:** Handle English-Hindi mixed sentences\n",
    "\n",
    "**2. Multi-Lingual Support**\n",
    "- üöÄ **Other Indic languages:** Extend to Bengali, Tamil, Telugu, Marathi\n",
    "- üöÄ **Unified interface:** Single model for all 22 Indian official languages\n",
    "- üöÄ **Language detection:** Auto-detect source language\n",
    "\n",
    "**3. Context-Aware Features**\n",
    "- üöÄ **Formality selection:** Let users choose formal/informal pronouns\n",
    "- üöÄ **Gender specification:** Allow gender context for accurate translation\n",
    "- üöÄ **Domain adaptation:** Provide domain-specific models (medical, legal, technical)\n",
    "\n",
    "**4. Quality Improvements**\n",
    "- üöÄ **Fine-tuning:** Fine-tune NLLB on additional English-Hindi data\n",
    "- üöÄ **Ensemble models:** Combine multiple models for better accuracy\n",
    "- üöÄ **Post-editing:** Add post-processing rules for common errors\n",
    "\n",
    "### Long-Term Vision (6-12 months)\n",
    "\n",
    "**1. Advanced Features**\n",
    "- üåü **Speech-to-Speech:** Integrate ASR (Automatic Speech Recognition) and TTS (Text-to-Speech)\n",
    "- üåü **Document translation:** Support PDF, DOCX, HTML with formatting preservation\n",
    "- üåü **Real-time subtitles:** Live translation for videos and meetings\n",
    "- üåü **Contextual translation:** Maintain context across multiple sentences/paragraphs\n",
    "\n",
    "**2. Responsible AI Enhancements**\n",
    "- üåü **Bias mitigation:** Implement debiasing techniques (counterfactual data augmentation)\n",
    "- üåü **Cultural adaptation:** Partner with linguists for culturally appropriate translations\n",
    "- üåü **Transparency tools:** Provide attention visualization, explain translation choices\n",
    "\n",
    "**3. Deployment & Scalability**\n",
    "- üåü **Cloud deployment:** Deploy on AWS/GCP/Azure with auto-scaling\n",
    "- üåü **Edge deployment:** Optimize for mobile/IoT devices\n",
    "- üåü **Offline mode:** Enable fully offline translation for low-connectivity areas\n",
    "\n",
    "**4. Research Directions**\n",
    "- üåü **Low-resource learning:** Explore few-shot learning for rare language pairs\n",
    "- üåü **Multimodal translation:** Integrate visual context (image + text translation)\n",
    "- üåü **Interactive translation:** Implement reinforcement learning from user feedback\n",
    "\n",
    "### Impact Goals\n",
    "\n",
    "**Educational Impact:**\n",
    "- Deploy in 1,000+ schools for student access to English resources\n",
    "- Partner with MOOC platforms (Coursera, edX) for multilingual courses\n",
    "\n",
    "**Government Impact:**\n",
    "- Integrate with Digital India portal for citizen services\n",
    "- Support Aadhaar-linked multilingual document access\n",
    "\n",
    "**Business Impact:**\n",
    "- Provide API for e-commerce platforms (Amazon, Flipkart)\n",
    "- Enable customer support in multiple languages\n",
    "\n",
    "**Research Impact:**\n",
    "- Publish findings at NLP conferences (ACL, EMNLP, NAACL)\n",
    "- Open-source codebase for community contributions\n",
    "\n",
    "---\n",
    "\n",
    "## Final Remarks\n",
    "\n",
    "This project demonstrates the **transformative potential of AI in breaking language barriers**. By combining state-of-the-art models (T5 + NLLB) in a hybrid pipeline, we achieve practical, real-world translation quality.\n",
    "\n",
    "The system is **production-ready for general-purpose use** while acknowledging limitations that require ongoing improvement. Ethical considerations around bias, fairness, and responsible deployment are central to ensuring this technology **serves humanity equitably**.\n",
    "\n",
    "**Key Takeaway:** Language technology is not just about algorithms‚Äîit's about **empowering people**, preserving **linguistic diversity**, and building a more **inclusive digital world**.\n",
    "\n",
    "---\n",
    "\n",
    "### References\n",
    "\n",
    "1. **NLLB Team (2022).** \"No Language Left Behind: Scaling Human-Centered Machine Translation.\" Meta AI Research.\n",
    "2. **Raffel et al. (2020).** \"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.\" JMLR.\n",
    "3. **Kunchukuttan et al. (2018).** \"The IIT Bombay English-Hindi Parallel Corpus.\" LREC.\n",
    "4. **Papineni et al. (2002).** \"BLEU: a Method for Automatic Evaluation of Machine Translation.\" ACL.\n",
    "5. **Post (2018).** \"A Call for Clarity in Reporting BLEU Scores.\" WMT.\n",
    "\n",
    "---\n",
    "\n",
    "**üôè Thank you for reviewing this notebook!**\n",
    "\n",
    "**üìß Contact:** vijay@example.com\n",
    "\n",
    "**üìÖ Last Updated:** January 17, 2026"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
